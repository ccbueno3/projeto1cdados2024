{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Caio Bueno\n",
    "\n",
    "Nome: Lucca Nicoletti\n",
    "\n",
    "Nome: João Andrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Dell\\Documents\\REPOSITORIO CDADOS 2024\\projeto1cdados2024\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The BCP lays out a detailed plan which‚ if cal...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If even a single bit of the data is changed, t...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Users, on the other hand, only need PCs (or te...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some common implementations of file transfer i...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A list is a series of data items that can be a...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target\n",
       "0  The BCP lays out a detailed plan which‚ if cal...     HG\n",
       "1  If even a single bit of the data is changed, t...     AI\n",
       "2  Users, on the other hand, only need PCs (or te...     HG\n",
       "3  Some common implementations of file transfer i...     AI\n",
       "4  A list is a series of data items that can be a...     HG"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dados_treino_TRIO_caiocb3.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are some of the key strengths and benefit...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Therefore, e-commerce sites need to have clear...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When a judge sees a digital signature, he or s...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This can significantly improve the speed of da...</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While these attacks coulddamage data directly ...</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence target\n",
       "0  Here are some of the key strengths and benefit...     AI\n",
       "1  Therefore, e-commerce sites need to have clear...     AI\n",
       "2  When a judge sees a digital signature, he or s...     HG\n",
       "3  This can significantly improve the speed of da...     AI\n",
       "4  While these attacks coulddamage data directly ...     HG"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('dados_teste_TRIO_caiocb3.csv')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o projeto 1 de Ciência de Dados, foi-se designado a criação de um classificador Naive-Bayes que pudesse distiguir uma frase entre \"gerada por humanos\" ou \"gerada por inteligência artificial\". Portanto, o uso de manipulação de Data Frame, montagem de classificador, filtragem de stop words e entre outros mecanismos de aperfeiçoamento serão utilizados no trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Antes da montagem do classificador, montamos 2 funções de limpeza de texto e remoção de stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "#função para limpar texto\n",
    "def cleanup(text):\n",
    "    punctuation = '[´\"-.:?;$'']'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "\n",
    "#função para remover stop words\n",
    "def limpandostopwords(frase):\n",
    "\n",
    "    # Importando lista de stop words necessarias em ingles\n",
    "\n",
    "    stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
    "'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', \n",
    "'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    " 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', \n",
    "'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
    "'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', \n",
    "'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \n",
    "'s', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y',\n",
    " 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", \n",
    "'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", \n",
    "'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "    #removendo stop words    \n",
    "    frase = frase.split()\n",
    "    sem_stop = ''\n",
    "    for palavra in frase:\n",
    "        if palavra in stop_words:\n",
    "            frase.remove(palavra)\n",
    "        else:\n",
    "            sem_stop += palavra + ' '\n",
    "    return sem_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Para o início do processo de classificação, é preciso separar a coluna de frases Data Frame conforme o tipo de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerada por humanos\n",
    "train_hg = train.loc[train['target'] == 'HG', ['sentence']]\n",
    "\n",
    "#gerada por ia\n",
    "train_ia = train.loc[train['target'] == 'AI', ['sentence']]\n",
    "\n",
    "#todas frases\n",
    "train_all = train.loc[:,['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista vazia para armazenar todas palavras (sem repetição)\n",
    "todas_palavras = []\n",
    "\n",
    "#limpando e armazenando\n",
    "for frase in train_all['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_palavras:\n",
    "            todas_palavras.append(palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, iremos calcular a probabilidade de cada palavra no conjunto universo do Data Frame de treino:\n",
    "$$P(palavra)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_palavra = {}\n",
    "\n",
    "for palavra in todas_palavras:\n",
    "    cont = 0 \n",
    "    for sentence in train_all['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((train_all['sentence']))\n",
    "        p_palavra[palavra] = probabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, repete-se o proceso para achar a probabilidade de cada palavra estar em uma frase classificada como \"gerada por IA\":\n",
    "$$P(palavra|AI)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_ia =  []\n",
    "p_palavra_ia = {}\n",
    "\n",
    "#cria uma lista com todas palavras que aparecem nas frases classificadas como 'ia' (sem repetições)\n",
    "for frase in train_ia['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_ia:\n",
    "            todas_ia.append(palavra)\n",
    "\n",
    "\n",
    "for palavra in todas_ia:\n",
    "    cont = 0 \n",
    "    for sentence in train_ia['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((train_ia['sentence']))\n",
    "        p_palavra_ia[palavra] = probabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E repetiremos novamente este passo para as frases classificadas como \"geradas por humanos\":\n",
    "$$P(palavra|HG)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_hg =  []\n",
    "p_palavra_hg = {}\n",
    "\n",
    "#cria uma lista com todas palavras que aparecem nas frases classificadas como 'ia' (sem repetições)\n",
    "for frase in train_hg['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_hg:\n",
    "            todas_hg.append(palavra)\n",
    "\n",
    "\n",
    "for palavra in todas_hg:\n",
    "    cont = 0 \n",
    "    for sentence in train_hg['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((train_hg['sentence']))\n",
    "        p_palavra_hg[palavra] = probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, será classificado a probabilidade de uma frase ser gerada por IA ou por humanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ia_train = len(train_ia['sentence'])/len(train_all['sentence'])\n",
    "prob_hg_train = len(train_hg['sentence'])/len(train_all['sentence'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, é hora de montar o Classificador para a base de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_treino(frase):\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    p_ia = 1\n",
    "    p_hg = 1\n",
    "\n",
    "    #iteração de palavras na frase para verificar qual \n",
    "    for palavra in palavras_frase:\n",
    "        if palavra in todas_ia:\n",
    "            p_ia *= p_palavra_ia[palavra]/p_palavra[palavra]\n",
    "        if palavra in todas_hg:\n",
    "            p_hg *= p_palavra_hg[palavra]/p_palavra[palavra]\n",
    "\n",
    "    p_ia *=prob_ia_train\n",
    "    p_hg *= prob_hg_train\n",
    "\n",
    "   \n",
    "    #para isso iremos classificar as frases geradas por IA como \"0\" e as frases geradas por humanos como \"1\"\n",
    "\n",
    "    if p_ia>p_hg:\n",
    "        return 0\n",
    "    if p_hg>p_ia:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a montagem do classificador, é necessário executa-lo com as frases de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.516349</td>\n",
       "      <td>0.023842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG</th>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.405313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0.0       1.0\n",
       "target                    \n",
       "AI      0.516349  0.023842\n",
       "HG      0.054496  0.405313"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_treino= []\n",
    "\n",
    "for frase in train_all['sentence']:\n",
    "    classificacao = classificador_treino(frase)\n",
    "    lista_treino.append(classificacao)\n",
    "pd.crosstab(train['target'],lista_treino,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela a tabela acima, podemos observar os valores no qual o classificador coincide com o target do Data frame, correspondem a valores verdadeiros (verdadeiros positivos e verdadeiros negativos).\n",
    "\n",
    ">Portanto a acurácia do classificador corresponde a soma de tal valores, ou seja, 92.1%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Realizado o classificador, é preciso refazer todos os passos para o data frame de Teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hg = test.loc[test['target'] == 'HG', ['sentence']]\n",
    "\n",
    "test_ia = test.loc[test['target'] == 'AI', ['sentence']]\n",
    "\n",
    "test_all = test.loc[:,['sentence']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista vazia para armazenar todas palavras (sem repetição)\n",
    "todas_palavras = []\n",
    "\n",
    "#limpando e armazenando\n",
    "for frase in test_all['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_palavras:\n",
    "            todas_palavras.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_palavra = {}\n",
    "\n",
    "for palavra in todas_palavras:\n",
    "    cont = 0 \n",
    "    for sentence in test_all['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((test_all['sentence']))\n",
    "        p_palavra[palavra] = probabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_ia =  []\n",
    "p_palavra_ia = {}\n",
    "\n",
    "#cria uma lista com todas palavras que aparecem nas frases classificadas como 'ia' (sem repetições)\n",
    "for frase in test_ia['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_ia:\n",
    "            todas_ia.append(palavra)\n",
    "\n",
    "\n",
    "for palavra in todas_ia:\n",
    "    cont = 0 \n",
    "    for sentence in test_ia['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((test_ia['sentence']))\n",
    "        p_palavra_ia[palavra] = probabilidade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_hg =  []\n",
    "p_palavra_hg = {}\n",
    "\n",
    "#cria uma lista com todas palavras que aparecem nas frases classificadas como 'ia' (sem repetições)\n",
    "for frase in test_hg['sentence']:\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    \n",
    "\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        if palavra not in todas_hg:\n",
    "            todas_hg.append(palavra)\n",
    "\n",
    "\n",
    "for palavra in todas_hg:\n",
    "    cont = 0 \n",
    "    for sentence in test_hg['sentence']:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = cleanup(sentence)\n",
    "        sentence = limpandostopwords(sentence)\n",
    "        split_sentence = sentence.split()\n",
    "\n",
    "        if palavra in split_sentence:\n",
    "            cont +=1\n",
    "        \n",
    "        probabilidade = cont/len((test_hg['sentence']))\n",
    "        p_palavra_hg[palavra] = probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ia_test = len(test_ia['sentence'])/len(test_all['sentence'])\n",
    "prob_hg_test = len(test_hg['sentence'])/len(test_all['sentence'])\n",
    "\n",
    "\n",
    "\n",
    "def classificador_teste(frase):\n",
    "    frase = frase.lower()\n",
    "    frase = cleanup(frase)\n",
    "    frase = limpandostopwords(frase)\n",
    "    palavras_frase = frase.split()\n",
    "\n",
    "    p_ia = 1\n",
    "    p_hg = 1\n",
    "\n",
    "    #iteração de palavras na frase para verificar qual \n",
    "    for palavra in palavras_frase:\n",
    "        if palavra in todas_ia:\n",
    "            p_ia *= p_palavra_ia[palavra]/p_palavra[palavra]\n",
    "        if palavra in todas_hg:\n",
    "            p_hg *= p_palavra_hg[palavra]/p_palavra[palavra]\n",
    "\n",
    "    p_ia *=prob_ia_test\n",
    "    p_hg *= prob_hg_test\n",
    "\n",
    "   \n",
    "    #para isso iremos classificar as frases geradas por IA como \"0\" e as frases geradas por humanos como \"1\"\n",
    "\n",
    "    if p_ia>p_hg:\n",
    "        return 0\n",
    "    if p_hg>p_ia:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.017460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.438095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0          0         1\n",
       "target                    \n",
       "AI      0.511111  0.017460\n",
       "HG      0.033333  0.438095"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_test= []\n",
    "\n",
    "for frase in test_all['sentence']:\n",
    "    classificacao = classificador_teste(frase)\n",
    "    lista_test.append(classificacao)\n",
    "pd.crosstab(test['target'],lista_test,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa-se, portanto, que a precisão do classificador para o Data Frame de testes é de 94,9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Conclui-se portanto que o nosso classficador possui 92,1% de precisão para o Data Frame de treino e 94,9% para o de testes, ou seja, a utilização de funções de limpeza da frase e remoção de stop words se demonstrou _POSITIVA_ visto que os resultados são de excelente acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
